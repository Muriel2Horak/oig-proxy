# AnalÃ½za frontovÃ¡nÃ­ dat bÄ›hem vÃ½padku cloudu

## KlÃ­ÄovÃ© zjiÅ¡tÄ›nÃ­ z protokolu

### 1. **Request-Response pattern**

```
08:59:07.309  BOX â†’ PROXY: tbl_dc_in frame
08:59:07.320  PROXY â†’ BOX: ACK (11ms delay)

08:59:12.777  BOX â†’ PROXY: tbl_ac_in frame
08:59:12.786  PROXY â†’ BOX: ACK (9ms delay)

08:59:17.420  BOX â†’ PROXY: tbl_ac_out frame
08:59:17.430  PROXY â†’ BOX: ACK (10ms delay)
```

**ZÃ¡vÄ›r:** BOX **NEPOSÃLÃ** dalÅ¡Ã­ frame dokud nedostane ACK!

### 2. **ACK je POTVRZENÃ pÅ™ijetÃ­ dat**

- Cloud posÃ­lÃ¡ ACK okamÅ¾itÄ› po pÅ™ijetÃ­ kaÅ¾dÃ©ho frame (8-15ms)
- BOX ÄekÃ¡ na ACK pÅ™ed odeslÃ¡nÃ­m dalÅ¡Ã­ho frame
- **ACK = "Data jsem pÅ™ijal a zpracoval"**

### 3. **Co se stane pÅ™i vÃ½padku cloudu?**

#### SouÄasnÃ½ stav (bez fallback mÃ³du):
```
BOX â†’ PROXY: tbl_actual frame
PROXY â†’ CLOUD: (connection failed)
PROXY: closes BOX socket âŒ
BOX: detects disconnect â†’ reconnect loop
```

**ProblÃ©m:** Data jsou ztracenÃ¡ navÅ¾dy! ğŸ“‰

#### S fallback mÃ³dem (bez frontovÃ¡nÃ­):
```
BOX â†’ PROXY: tbl_actual frame
PROXY: cloud offline, send local ACK âœ…
BOX: happy, continues sending

PROXY â†’ MQTT: publish data âœ…
BOX â†’ PROXY: next frame (after ~9s)
```

**VÃ½sledek:** Data jdou do MQTT, ale CLOUD je nikdy neuvidÃ­ ğŸ“Š

#### S frontovÃ¡nÃ­m (queue mode):
```
BOX â†’ PROXY: tbl_actual frame
PROXY: cloud offline, QUEUE frame + send ACK âœ…
BOX: happy, continues sending

PROXY â†’ MQTT: publish data âœ…
PROXY â†’ QUEUE: store frame for replay

--- cloud is back ---
PROXY: cloud online! ğŸ‰
PROXY â†’ CLOUD: replay queued frames
CLOUD â†’ PROXY: ACK for each queued frame
```

**VÃ½sledek:** Data v MQTT i v CLOUDu! ğŸš€

---

## OtÃ¡zka 1: Je tam potvrzenÃ­ z cloudu?

**ANO! ACK je potvrzenÃ­!** âœ…

```xml
BOX â†’ CLOUD: <Frame><TblName>tbl_actual</TblName>...data...</Frame>
CLOUD â†’ BOX: <Frame><Result>ACK</Result><ToDo>GetActual</ToDo><CRC>00167</CRC></Frame>
```

**VÃ½znam:**
- ACK = "Data jsem pÅ™ijal a zpracoval"
- BOX ÄekÃ¡ na ACK pÅ™ed odeslÃ¡nÃ­m dalÅ¡Ã­ho frame
- Bez ACK se BOX "zasekne" a ÄekÃ¡ (nebo timeout)

---

## OtÃ¡zka 2: MusÃ­me pÅ™i vÃ½padku taky posÃ­lat ACK?

**ANO, ABSOLUTNÄš!** âœ…âœ…âœ…

### ProÄ musÃ­me posÃ­lat ACK bÄ›hem offline mÃ³du:

1. **BOX ÄekÃ¡ na ACK**
   - Pokud nedostane ACK â†’ timeout â†’ disconnect
   - KaÅ¾dÃ½ frame MUSÃ dostat ACK odpovÄ›Ä

2. **ACK je souÄÃ¡stÃ­ protokolu**
   - NenÃ­ to jen "nice to have"
   - Je to **povinnÃ¡ souÄÃ¡st** request-response cyklu

3. **Bez ACK = mrtvÃ© spojenÃ­**
   ```
   BOX â†’ PROXY: tbl_actual
   PROXY: ... (silence) ...
   BOX: timeout after 30s? 60s?
   BOX: disconnect â†’ reconnect loop âŒ
   ```

### SprÃ¡vnÃ½ offline mÃ³d:

```python
async def _run_offline_mode(self, conn_id, box_reader, box_writer):
    '''Offline mode with ACK generation'''
    
    while True:
        # Read frame from BOX
        data = await asyncio.wait_for(box_reader.read(8192), timeout=120.0)
        
        # Parse frame
        frame = data.decode('utf-8', errors='ignore')
        table_name = self._extract_table_name(frame)
        
        # CRITICAL: Send ACK immediately!
        ack_response = self._generate_ack(table_name)  # ACK or END
        box_writer.write(ack_response.encode('utf-8'))
        await box_writer.drain()
        
        # THEN process (MQTT, queue, etc.)
        await self._process_frame(frame, conn_id, table_name)
```

**PoÅ™adÃ­ je klÃ­ÄovÃ©:**
1. âœ… PÅ™ijmi frame od BOXu
2. âœ… **OKAMÅ½ITÄš** poÅ¡li ACK zpÄ›t
3. âœ… Teprve pak zpracuj (MQTT, fronta, atd.)

---

## FrontovÃ¡nÃ­ dat - moÅ¾nosti

### MoÅ¾nost A: Bez frontovÃ¡nÃ­ (Simple)

```python
async def _process_frame(self, frame, conn_id, table_name):
    # Publish to MQTT
    await self._publish_to_mqtt(frame, table_name)
    
    # That's it! No cloud, no queue
    logger.info(f"[#{conn_id}] Published {table_name} to MQTT (cloud offline)")
```

**VÃ½hody:**
- JednoduchÃ¡ implementace
- Å½Ã¡dnÃ¡ pamÄ›Å¥ovÃ¡ zÃ¡tÄ›Å¾
- Data okamÅ¾itÄ› v MQTT

**NevÃ½hody:**
- Cloud nikdy neuvidÃ­ data z outage periody
- ChybÄ›jÃ­cÃ­ historie na cloudu
- PotenciÃ¡lnÃ­ reporting gaps

---

### MoÅ¾nost B: S frontovÃ¡nÃ­m (Resilient)

```python
class OfflineQueue:
    def __init__(self):
        self.queue = []  # List of (timestamp, frame, table_name)
        self.max_size = 10000  # Max 10k frames (~4 hours outage)
    
    def add(self, frame, table_name):
        '''Add frame to queue'''
        if len(self.queue) < self.max_size:
            self.queue.append((time.time(), frame, table_name))
            logger.debug(f"Queued {table_name}, queue size: {len(self.queue)}")
        else:
            # Queue full - drop oldest
            dropped = self.queue.pop(0)
            self.queue.append((time.time(), frame, table_name))
            logger.warning(f"Queue full! Dropped {dropped[2]} from {dropped[0]}")
    
    def get_all(self):
        '''Get all queued frames and clear'''
        frames = self.queue.copy()
        self.queue.clear()
        return frames


async def _run_offline_mode(self, conn_id, box_reader, box_writer):
    '''Offline mode with queueing'''
    
    queue = OfflineQueue()
    
    while True:
        # Read frame
        data = await asyncio.wait_for(box_reader.read(8192), timeout=120.0)
        frame = data.decode('utf-8', errors='ignore')
        table_name = self._extract_table_name(frame)
        
        # Send ACK immediately
        ack = self._generate_ack(table_name)
        box_writer.write(ack.encode('utf-8'))
        await box_writer.drain()
        
        # Publish to MQTT
        await self._publish_to_mqtt(frame, table_name)
        
        # Add to queue
        queue.add(frame, table_name)
        
        # Check cloud status (non-blocking)
        if self.cloud_is_online:
            # Switch to forward mode
            await self._replay_queue(queue)
            break


async def _replay_queue(self, queue):
    '''Replay queued frames to cloud'''
    
    frames = queue.get_all()
    
    if not frames:
        logger.info("No queued frames to replay")
        return
    
    logger.info(f"Replaying {len(frames)} queued frames to cloud...")
    
    # Open cloud connection
    cloud_reader, cloud_writer = await asyncio.open_connection(
        TARGET_SERVER, TARGET_PORT
    )
    
    try:
        for ts, frame, table_name in frames:
            # Send frame to cloud
            cloud_writer.write(frame.encode('utf-8'))
            await cloud_writer.drain()
            
            # Wait for ACK from cloud
            response = await asyncio.wait_for(
                cloud_reader.read(8192),
                timeout=5.0
            )
            
            # Verify ACK
            if b'<Result>ACK</Result>' in response:
                logger.debug(f"Cloud ACKed queued {table_name} from {ts}")
            else:
                logger.warning(f"Cloud did not ACK queued {table_name}")
        
        logger.info(f"Successfully replayed {len(frames)} frames to cloud")
    
    except Exception as e:
        logger.error(f"Error replaying queue: {e}")
        # Re-queue failed frames?
    
    finally:
        cloud_writer.close()
        await cloud_writer.wait_closed()
```

**VÃ½hody:**
- Cloud dostane vÅ¡echna data (i z outage)
- KompletnÃ­ historie
- Data persistence

**NevÃ½hody:**
- SloÅ¾itÄ›jÅ¡Ã­ implementace
- PamÄ›Å¥ovÃ¡ zÃ¡tÄ›Å¾ (10k frames = ~10MB)
- Replay logika

---

### MoÅ¾nost C: FrontovÃ¡nÃ­ do SQLite (Persistent)

```python
import aiosqlite

class PersistentQueue:
    def __init__(self, db_path='/data/offline_queue.db'):
        self.db_path = db_path
    
    async def init(self):
        async with aiosqlite.connect(self.db_path) as db:
            await db.execute('''
                CREATE TABLE IF NOT EXISTS queue (
                    id INTEGER PRIMARY KEY AUTOINCREMENT,
                    ts TEXT,
                    table_name TEXT,
                    frame TEXT,
                    replayed INTEGER DEFAULT 0
                )
            ''')
            await db.commit()
    
    async def add(self, frame, table_name):
        async with aiosqlite.connect(self.db_path) as db:
            await db.execute(
                'INSERT INTO queue (ts, table_name, frame) VALUES (?, ?, ?)',
                (datetime.utcnow().isoformat(), table_name, frame)
            )
            await db.commit()
    
    async def get_pending(self):
        async with aiosqlite.connect(self.db_path) as db:
            cursor = await db.execute(
                'SELECT id, ts, table_name, frame FROM queue WHERE replayed = 0 ORDER BY id'
            )
            return await cursor.fetchall()
    
    async def mark_replayed(self, frame_id):
        async with aiosqlite.connect(self.db_path) as db:
            await db.execute(
                'UPDATE queue SET replayed = 1 WHERE id = ?',
                (frame_id,)
            )
            await db.commit()
```

**VÃ½hody:**
- Data pÅ™eÅ¾ijÃ­ proxy restart
- NeomezenÃ¡ fronta (disk space)
- Audit trail (mÅ¯Å¾eÅ¡ vidÄ›t co bylo replayed)

**NevÃ½hody:**
- I/O overhead (disk writes)
- SloÅ¾itÄ›jÅ¡Ã­ cleanup logika
- Database maintenance

---

## DoporuÄenÃ­

### FÃ¡ze 1: Simple offline mode (bez frontovÃ¡nÃ­) âœ… RECOMMENDED

```python
# Implementuj:
1. Offline mode s lokÃ¡lnÃ­m ACK
2. MQTT publishing bÄ›hem offline
3. Cloud reconnect probes

# NEIMPLEMENTUJ:
- FrontovÃ¡nÃ­ (zatÃ­m)
- Replay logiku
```

**ProÄ:**
- RychlÃ¡ implementace
- OkamÅ¾itÃ½ benefit (data v MQTT bÄ›hem outage)
- Å½Ã¡dnÃ¡ data loss v MQTT
- Cloud data loss je pÅ™ijatelnÃ½ (outage je rare)

### FÃ¡ze 2: Queue mode (s frontovÃ¡nÃ­m) ğŸ”œ FUTURE

```python
# Po ÃºspÄ›Å¡nÃ© fÃ¡zi 1 pÅ™idej:
1. In-memory queue (10k frames limit)
2. Replay logiku po cloud recovery
3. Metrics (queue size, replay success rate)
```

**ProÄ pozdÄ›ji:**
- KomplexnÄ›jÅ¡Ã­ implementace
- PotÅ™ebuje testovÃ¡nÃ­ (edge cases)
- NenÃ­ kritickÃ© (MQTT mÃ¡ data)

---

## Odhad velikosti fronty

### TypickÃ½ outage scÃ©nÃ¡Å™:

```
Outage dÃ©lka: 10 minut
Telemetry rate: ~10 framÅ¯/min (tbl_actual + others)
Total frames: 10 min Ã— 10 frames/min = 100 frames
Frame size: ~500 bytes average
Total memory: 100 Ã— 500B = 50 KB
```

**ZÃ¡vÄ›r:** FrontovÃ¡nÃ­ 10min outage = **~50 KB** (zanedbatelnÃ©)

### Extreme outage scÃ©nÃ¡Å™:

```
Outage dÃ©lka: 4 hodiny (extreme!)
Telemetry rate: ~10 framÅ¯/min
Total frames: 240 min Ã— 10 frames/min = 2400 frames
Total memory: 2400 Ã— 500B = 1.2 MB
```

**ZÃ¡vÄ›r:** I 4h outage = **~1.2 MB** (stÃ¡le OK)

### Queue limit doporuÄenÃ­:

```python
MAX_QUEUE_SIZE = 10000  # ~5 MB, covers ~16 hours outage
```

---

## ImplementaÄnÃ­ priority

### P0 (CRITICAL - implementuj teÄ):
- âœ… Offline mode s lokÃ¡lnÃ­m ACK generation
- âœ… MQTT publishing bÄ›hem offline
- âœ… Cloud reconnect probes

### P1 (HIGH - implementuj brzy):
- ğŸ”œ In-memory queue (simple list)
- ğŸ”œ Replay logiku po cloud recovery
- ğŸ”œ Queue size metrics

### P2 (MEDIUM - mÅ¯Å¾eÅ¡ implementovat pozdÄ›ji):
- ğŸ“… Persistent queue (SQLite)
- ğŸ“… Intelligent replay (rate limiting)
- ğŸ“… Queue cleanup policy

### P3 (LOW - nice to have):
- ğŸ’¡ Compression (gzip frames v queue)
- ğŸ’¡ Deduplication (pokud stejnÃ½ frame vÃ­cekrÃ¡t)
- ğŸ’¡ Priority queue (tbl_actual first, then others)

---

## ZÃ¡vÄ›reÄnÃ© doporuÄenÃ­

### 1. **MusÃ­me posÃ­lat ACK?**
   **ANO!** ACK je povinnÃ¡ souÄÃ¡st protokolu. Bez ACK se BOX zasekne.

### 2. **MusÃ­me frontovat data?**
   **Ne nutnÄ› v prvnÃ­ fÃ¡zi.** 
   
   Start simple:
   - Offline mode + ACK âœ…
   - MQTT publishing âœ…
   - Cloud dostane data aÅ¾ po recovery (missing gap)
   
   Later add:
   - Queue + replay ğŸ”œ
   - Cloud dostane vÅ¡echna data (no gap)

### 3. **Jak implementovat ACK bÄ›hem offline?**
   ```python
   def _generate_ack(self, table_name):
       if table_name == 'IsNewSet':
           return '<Frame><Result>END</Result><CRC>34500</CRC></Frame>'
       else:
           return '<Frame><Result>ACK</Result><ToDo>GetActual</ToDo><CRC>00167</CRC></Frame>'
   ```

### 4. **DoporuÄenÃ½ pÅ™Ã­stup:**
   
   **FÃ¡ze 1 (teÄ):**
   - Implementuj offline mode s ACK
   - MQTT publishing
   - Cloud reconnect
   - **Bez frontovÃ¡nÃ­**
   
   **FÃ¡ze 2 (pozdÄ›ji):**
   - PÅ™idej in-memory queue
   - Replay logiku
   - Metrics
   
   **FÃ¡ze 3 (budoucnost):**
   - Persistent queue
   - Advanced replay strategies

---

## Timeline estimate

### FÃ¡ze 1 (bez frontovÃ¡nÃ­):
- Implementation: 2-3 hodiny
- Testing: 1 hodina
- Deploy + monitor: 1 den
- **Total: ~1 den prÃ¡ce**

### FÃ¡ze 2 (s frontovÃ¡nÃ­m):
- Implementation: 3-4 hodiny
- Testing: 2 hodiny (edge cases!)
- Deploy + monitor: 2 dny
- **Total: ~2-3 dny prÃ¡ce**

**DoporuÄenÃ­: Start s FÃ¡ze 1, evaluovat po tÃ½dnu provozu** âœ…
